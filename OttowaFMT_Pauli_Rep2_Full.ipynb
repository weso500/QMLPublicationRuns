{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1aliltLjDEnxzvpA5ukuggO0o36ITX22a",
      "authorship_tag": "ABX9TyPwwCLsX8MDZQz9ThATz0bO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weso500/QMLPublicationRuns/blob/main/OttowaFMT_Pauli_Rep2_Full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install qiskit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgyNUORwX7zC",
        "outputId": "0a7687fd-8654-4d9b-c931-9fbfffaf1a78"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.2.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.2)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.5.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Downloading qiskit-2.2.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stevedore, rustworkx, qiskit\n",
            "Successfully installed qiskit-2.2.2 rustworkx-0.17.1 stevedore-5.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install qiskit-machine-learning"
      ],
      "metadata": {
        "id": "hFPHrg0sYSqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cef319c-ab39-48ac-cc7b-a82b612caca2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit-machine-learning\n",
            "  Downloading qiskit_machine_learning-0.8.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting qiskit<2.0,>=1.0 (from qiskit-machine-learning)\n",
            "  Downloading qiskit-1.4.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (2.0.2)\n",
            "Collecting scipy<1.16,>=1.4 (from qiskit-machine-learning)\n",
            "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (75.2.0)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (0.3.8)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit<2.0,>=1.0->qiskit-machine-learning) (0.17.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.12/dist-packages (from qiskit<2.0,>=1.0->qiskit-machine-learning) (1.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit<2.0,>=1.0->qiskit-machine-learning) (2.9.0.post0)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit<2.0,>=1.0->qiskit-machine-learning) (5.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit<2.0,>=1.0->qiskit-machine-learning) (4.15.0)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit<2.0,>=1.0->qiskit-machine-learning)\n",
            "  Downloading symengine-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit-machine-learning) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit-machine-learning) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit<2.0,>=1.0->qiskit-machine-learning) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.3->qiskit<2.0,>=1.0->qiskit-machine-learning) (1.3.0)\n",
            "Downloading qiskit_machine_learning-0.8.4-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit-1.4.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, scipy, qiskit, qiskit-machine-learning\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.2\n",
            "    Uninstalling scipy-1.16.2:\n",
            "      Successfully uninstalled scipy-1.16.2\n",
            "  Attempting uninstall: qiskit\n",
            "    Found existing installation: qiskit 2.2.2\n",
            "    Uninstalling qiskit-2.2.2:\n",
            "      Successfully uninstalled qiskit-2.2.2\n",
            "Successfully installed qiskit-1.4.5 qiskit-machine-learning-0.8.4 scipy-1.15.3 symengine-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyreadr"
      ],
      "metadata": {
        "id": "b-Cs-Mu7PwNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e37d2d50-79ce-4460-8899-96d1d97da8aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyreadr\n",
            "  Downloading pyreadr-0.5.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from pyreadr) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadr) (1.17.0)\n",
            "Downloading pyreadr-0.5.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (418 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.3/418.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyreadr\n",
            "Successfully installed pyreadr-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyreadr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hNpe4-x7P0Xe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the training data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/QMLIIOT/Train_11_final.csv')\n",
        "\n",
        "# Load the test data\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/QMLIIOT/Test_11_final.csv')\n"
      ],
      "metadata": {
        "id": "_6bikTGNRbX_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from qiskit.circuit.library import ZZFeatureMap\n",
        "from qiskit.circuit.library import PauliFeatureMap\n",
        "from qiskit.primitives import StatevectorSampler as Sampler\n",
        "from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
        "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
        "\n",
        "dimension = 11\n",
        "feature_map = PauliFeatureMap(feature_dimension=dimension, reps=2, entanglement=\"full\")\n",
        "\n",
        "sampler = Sampler()\n",
        "\n",
        "fidelity = ComputeUncompute(sampler=sampler)\n",
        "\n",
        "kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)"
      ],
      "metadata": {
        "id": "Isf2HH1kYigi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn import metrics\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# === Define helper for one trial ===\n",
        "def run_trial(i):\n",
        "\n",
        "    # Convert training features to numpy array and select 100 samples\n",
        "    train_features = train_df.sample(n=100, random_state=i).to_numpy()\n",
        "\n",
        "    # Randomly sample 50 from the first 500 and 5 from the last 100 (500-600)\n",
        "    test_features_normal = test_df.iloc[:500].sample(n=70, random_state=i).to_numpy()\n",
        "    test_features_anomaly = test_df.iloc[500:600].sample(n=5, random_state=i).to_numpy()\n",
        "    test_features = np.concatenate((test_features_normal, test_features_anomaly))\n",
        "\n",
        "    # Create target arrays for training and testing data\n",
        "    test_target = np.concatenate((np.zeros(70), np.ones(5)))\n",
        "\n",
        "    # --- Nyström approximation of the quantum kernel ---\n",
        "    n_components = min(64, len(train_features)-1)\n",
        "    Phi = Nystroem(\n",
        "        kernel=lambda A,B=None: kernel.evaluate(x_vec=A, y_vec=B),\n",
        "        n_components=n_components,\n",
        "        random_state=i\n",
        "    )\n",
        "    Ztr = Phi.fit_transform(train_features)\n",
        "    Zte = Phi.transform(test_features)\n",
        "\n",
        "    # Compute approximate Gram matrices for precomputed OCSVM\n",
        "    Ktr = Ztr @ Ztr.T\n",
        "    Kte = Zte @ Ztr.T\n",
        "\n",
        "    ocsvm = OneClassSVM(kernel='precomputed')\n",
        "    ocsvm.fit(Ktr)\n",
        "    scores = -ocsvm.decision_function(Kte)\n",
        "\n",
        "    fpr, tpr, _ = metrics.roc_curve(test_target, scores, pos_label=1)\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "    print(auc)\n",
        "    return auc\n",
        "\n",
        "# === Run in parallel ===\n",
        "aucs = Parallel(n_jobs=8)(delayed(run_trial)(i) for i in range(1))\n",
        "print(f\"\\nMean AUC={np.mean(aucs):.3f} ± {np.std(aucs):.3f}\")"
      ],
      "metadata": {
        "id": "iFHJfhFzaV5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c75bcd7-bf1d-4afa-ef99-f48135b800b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean AUC=0.740 ± 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn import metrics\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# ---- Helper: 95% CI for a 1D array-like\n",
        "def mean_ci(arr, alpha=0.05):\n",
        "    arr = np.asarray(arr, dtype=float)\n",
        "    n = len(arr)\n",
        "    m = np.mean(arr)\n",
        "    s = np.std(arr, ddof=1) if n > 1 else 0.0\n",
        "    z = 1.96  # normal approximation\n",
        "    half = z * (s / np.sqrt(max(n, 1)))\n",
        "    return m, m - half, m + half\n",
        "\n",
        "def youden_threshold(y_true, scores):\n",
        "    \"\"\"Return the threshold that maximizes Youden's J = TPR - FPR.\"\"\"\n",
        "    fpr, tpr, thr = metrics.roc_curve(y_true, scores, pos_label=1)\n",
        "    # Avoid non-finite thresholds (first element can be inf)\n",
        "    mask = np.isfinite(thr)\n",
        "    fpr, tpr, thr = fpr[mask], tpr[mask], thr[mask]\n",
        "    j = tpr - fpr\n",
        "    if len(j) == 0:\n",
        "        # fallback: median score if something degenerate happens\n",
        "        return np.median(scores)\n",
        "    idx = np.argmax(j)\n",
        "    return thr[idx]\n",
        "\n",
        "# === Define helper for one trial ===\n",
        "def run_trial(i, fault_id=1, n_train_normals=100, n_test_normals=70, n_test_faulty=5, nystrom_components=64, nu=0.05):\n",
        "    rng = np.random.RandomState(i)\n",
        "    sc = StandardScaler()\n",
        "\n",
        "    # Convert training features to numpy array and select 100 samples\n",
        "    train_features = train_df.sample(n=100, random_state=i).to_numpy()\n",
        "\n",
        "    # Randomly sample 50 from the first 500 and 5 from the last 100 (500-600)\n",
        "    test_features_normal = test_df.iloc[:500].sample(n=70, random_state=i).to_numpy()\n",
        "    test_features_anomaly = test_df.iloc[500:600].sample(n=5, random_state=i).to_numpy()\n",
        "    test_features = np.concatenate((test_features_normal, test_features_anomaly))\n",
        "\n",
        "    # Create target arrays for training and testing data\n",
        "    y_true = np.concatenate((np.zeros(70), np.ones(5)))\n",
        "\n",
        "    # --- Nyström approximation of the quantum kernel ---\n",
        "    n_components = min(nystrom_components, len(train_features) - 1)\n",
        "    Phi = Nystroem(\n",
        "        kernel=lambda A, B=None: kernel.evaluate(x_vec=A, y_vec=B),\n",
        "        n_components=n_components,\n",
        "        random_state=i\n",
        "    )\n",
        "    Ztr = Phi.fit_transform(train_features)\n",
        "    Zte = Phi.transform(test_features)\n",
        "\n",
        "    # Precomputed Gram matrices\n",
        "    Ktr = Ztr @ Ztr.T\n",
        "    Kte = Zte @ Ztr.T\n",
        "\n",
        "    # One-Class SVM (nu ~ anomaly prior)\n",
        "    ocsvm = OneClassSVM(kernel='precomputed', nu=nu)\n",
        "    ocsvm.fit(Ktr)\n",
        "\n",
        "    # Scores: higher = more anomalous\n",
        "    scores = -ocsvm.decision_function(Kte)\n",
        "\n",
        "    # --- Threshold-free metrics\n",
        "    roc_auc = metrics.roc_auc_score(y_true, scores)\n",
        "    pr_auc  = metrics.average_precision_score(y_true, scores)\n",
        "\n",
        "    # --- Youden-optimal threshold\n",
        "    thr = youden_threshold(y_true, scores)\n",
        "    y_pred = (scores >= thr).astype(int)  # 1 = anomaly\n",
        "\n",
        "    precision = metrics.precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall    = metrics.recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1        = metrics.f1_score(y_true, y_pred, zero_division=0)\n",
        "    accuracy  = metrics.accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return {\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"threshold\": thr\n",
        "    }\n",
        "\n",
        "# === Run in parallel ===\n",
        "N_RUNS = 30\n",
        "results = Parallel(n_jobs=8)(\n",
        "    delayed(run_trial)(i, fault_id=1, n_train_normals=100, n_test_normals=70, n_test_faulty=5,\n",
        "                       nystrom_components=64, nu=0.05)\n",
        "    for i in range(N_RUNS)\n",
        ")\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# === Summaries with 95% CI ===\n",
        "summary_rows = []\n",
        "for metric in [\"roc_auc\", \"pr_auc\", \"precision\", \"recall\", \"f1\", \"accuracy\", \"threshold\"]:\n",
        "    m, lo, hi = mean_ci(df[metric].values)\n",
        "    summary_rows.append({\"metric\": metric, \"mean\": m, \"ci95_lo\": lo, \"ci95_hi\": hi})\n",
        "\n",
        "summary = pd.DataFrame(summary_rows).set_index(\"metric\")\n",
        "\n",
        "print(\"\\n=== Cross-run metrics (mean ± 95% CI) using Youden-optimal threshold ===\")\n",
        "for metric, row in summary.iterrows():\n",
        "    if metric == \"threshold\":\n",
        "        print(f\"{metric:>9}: {row['mean']:.4f}  (95% CI: {row['ci95_lo']:.4f} .. {row['ci95_hi']:.4f})\")\n",
        "    else:\n",
        "        print(f\"{metric:>9}: {row['mean']:.3f}  (95% CI: {row['ci95_lo']:.3f} .. {row['ci95_hi']:.3f})\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vwyyY8fRjTmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9fc1955-5d9a-4244-98b4-db616ab66b3f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Cross-run metrics (mean ± 95% CI) using Youden-optimal threshold ===\n",
            "  roc_auc: 0.582  (95% CI: 0.538 .. 0.627)\n",
            "   pr_auc: 0.150  (95% CI: 0.119 .. 0.182)\n",
            "precision: 0.224  (95% CI: 0.128 .. 0.320)\n",
            "   recall: 0.740  (95% CI: 0.646 .. 0.834)\n",
            "       f1: 0.235  (95% CI: 0.209 .. 0.262)\n",
            " accuracy: 0.614  (95% CI: 0.533 .. 0.695)\n",
            "threshold: 0.0001  (95% CI: 0.0001 .. 0.0001)\n"
          ]
        }
      ]
    }
  ]
}